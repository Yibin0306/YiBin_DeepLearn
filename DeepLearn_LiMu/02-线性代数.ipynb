{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. 特征值、特征向量求解\n",
    "    下图为对矩阵求特征值、求特征向量的相关操作。"
   ],
   "id": "98bd0cf43982dda1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img.png)",
   "id": "666e86b18617e9d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. 标量运算",
   "id": "cccd45c421ee6078"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img_1.png)",
   "id": "4b7cdd126365bc19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. 向量运算\n",
    "    下图中，α是一个标量，\n",
    "    是把向量b拉长。"
   ],
   "id": "ea341aa96d9bff1a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img_2.png)",
   "id": "d2529aaf0f13f1e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img_3.png)",
   "id": "785a85d08377b439"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img_4.png)",
   "id": "7a3001a18566e1c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. 矩阵运算",
   "id": "a954a88d262e4cb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img_5.png)",
   "id": "a532f4d696763f09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img_6.png)",
   "id": "74e81e69081b96c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img_7.png)",
   "id": "37bb9d092f35a15a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img_8.png)",
   "id": "e5b3ba7038c78f12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    矩阵长度叫范数，下图为矩阵范数满足的公式。",
   "id": "9508756f1aa40341"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img_9.png)",
   "id": "b5ccc5018dbc173"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img_10.png)",
   "id": "d8a43ffb34f642d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img_11.png)",
   "id": "99dcf37c33bb26c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 5. 特征向量、特征值\n",
    "    红色、绿色向量都被一个矩阵作用后，红色的大小和方向都被改变了，绿色的仅被改变了大小，没有改变方向。绿色向量为矩阵的特征向量。"
   ],
   "id": "92131f0c1e883ab0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/02-线性代数/img_12.png)",
   "id": "c26d14502f87560e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 6. 线性代数\n",
    "## 6.1 标量\n",
    "    标量由只有一个元素的张量表示。"
   ],
   "id": "8c5aabff9e4ab74c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.230874Z",
     "start_time": "2025-07-23T06:27:16.221965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([3.0])\n",
    "y = torch.tensor([2.0])\n",
    "\n",
    "x + y, x * y, x / y, x ** y"
   ],
   "id": "3d4fc955beefe73d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.]), tensor([6.]), tensor([1.5000]), tensor([9.]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.2 向量\n",
    "### 6.2.1 创建向量\n",
    "    可以将向量视为标量值组成的列表。"
   ],
   "id": "cdbc6b493eb3691d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.262894Z",
     "start_time": "2025-07-23T06:27:16.248177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.arange(4)\n",
    "x"
   ],
   "id": "234d8681436a276f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.2.2 访问向量元素\n",
    "    通过张量的索引来访问任一元素。"
   ],
   "id": "776b038b4f36b6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.309100Z",
     "start_time": "2025-07-23T06:27:16.294690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "x = torch.arange(4)\n",
    "print(x[3])  # 索引从0开始"
   ],
   "id": "16aba4542d5eab2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.2.3 访问向量长度\n",
    "    访问张量的长度。"
   ],
   "id": "122196792f3e4f55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.356935Z",
     "start_time": "2025-07-23T06:27:16.341891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "x = torch.arange(4)\n",
    "len(x)"
   ],
   "id": "75d46a477cab2bf4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.2.4 访问向量维度\n",
    "    只有一个轴的张量，形状只有一个元素。"
   ],
   "id": "3e37b45c735256d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.403819Z",
     "start_time": "2025-07-23T06:27:16.389347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "x = torch.arange(4)\n",
    "x.shape"
   ],
   "id": "144feef23dd0fc5a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.3 矩阵\n",
    "### 6.3.1 创建矩阵\n",
    "    通过指定两个分量m和n来创建一个形状为m×n的矩阵。"
   ],
   "id": "102b9cb0c552a12f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.419459Z",
     "start_time": "2025-07-23T06:27:16.411607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20).reshape(5, 4)\n",
    "A"
   ],
   "id": "54c0823b419ef627",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.2 矩阵转置\n",
    "    矩阵的转置。"
   ],
   "id": "6df8a8ca32efe703"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.513399Z",
     "start_time": "2025-07-23T06:27:16.499801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A = torch.arange(20).reshape(5, 4)\n",
    "A.T # 矩阵的转置"
   ],
   "id": "48a6e2815faab753",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.3 对称矩阵\n",
    "对称矩阵（symmetric matrix）A 等于其转置：$A = A^{T}$"
   ],
   "id": "fb7c094a9ba592bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.639639Z",
     "start_time": "2025-07-23T06:27:16.625605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "B = torch.tensor([[1, 2, 3], [2, 0, 4],[3 ,4 ,5]])\n",
    "print(B)\n",
    "print(B == B.T)"
   ],
   "id": "dea75d4642117cf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 0, 4],\n",
      "        [3, 4, 5]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.4 多维矩阵\n",
    "    就像向量是标量的推广，矩阵是向量的推广一样，可以构建更多轴的数据结构。"
   ],
   "id": "7795f815da4d2f71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.732998Z",
     "start_time": "2025-07-23T06:27:16.719162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "print(X)"
   ],
   "id": "73068b89ce7e10b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.5 矩阵克隆\n",
    "    给定具有相同形状的任何两个张量，任何按元素二元运算的结果都将是相同形状的张量。"
   ],
   "id": "5551699949bba2c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.779461Z",
     "start_time": "2025-07-23T06:27:16.764602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "B = A.clone() # 通过分配新内存，将A的一个副本分配给B\n",
    "print(A)\n",
    "print(A + B)"
   ],
   "id": "2ce5b037f8eaae76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "tensor([[ 0.,  2.,  4.,  6.],\n",
      "        [ 8., 10., 12., 14.],\n",
      "        [16., 18., 20., 22.],\n",
      "        [24., 26., 28., 30.],\n",
      "        [32., 34., 36., 38.]])\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.6 矩阵相乘（对应元素相乘）\n",
    "    两个句子的按元素乘法称为哈达玛积（Hadamard product）（数学符号⊙）"
   ],
   "id": "9512d9a16b6ee9f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.825297Z",
     "start_time": "2025-07-23T06:27:16.811285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20,dtype=torch.float32).reshape(5,4)\n",
    "B = A.clone() # 通过分配新内存，将A的一个副本分配给B\n",
    "print(A)\n",
    "print(A * B)"
   ],
   "id": "874d898b11f8f7ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "tensor([[  0.,   1.,   4.,   9.],\n",
      "        [ 16.,  25.,  36.,  49.],\n",
      "        [ 64.,  81., 100., 121.],\n",
      "        [144., 169., 196., 225.],\n",
      "        [256., 289., 324., 361.]])\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.3.7 矩阵加标量",
   "id": "bf358517a102d5fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.856370Z",
     "start_time": "2025-07-23T06:27:16.842584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = 2\n",
    "X =  torch.arange(24).reshape(2, 3, 4)\n",
    "print(a + X)\n",
    "print((a * X).shape)"
   ],
   "id": "3dbcd6b6f5b63b38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9],\n",
      "         [10, 11, 12, 13]],\n",
      "\n",
      "        [[14, 15, 16, 17],\n",
      "         [18, 19, 20, 21],\n",
      "         [22, 23, 24, 25]]])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.3.8 向量求和\n",
    "    计算所有元素的和。"
   ],
   "id": "78788bba06f2e7b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.903801Z",
     "start_time": "2025-07-23T06:27:16.890649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.arange(4,dtype=torch.float32)\n",
    "print(x)\n",
    "print(x.sum())"
   ],
   "id": "2db08e8a3e2fa1c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.])\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.9 矩阵求和\n",
    "    表示任意形状张量的元素和。"
   ],
   "id": "391a30f26dbcca8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.950082Z",
     "start_time": "2025-07-23T06:27:16.936033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20*2).reshape(2,5,4)\n",
    "print(A.shape)\n",
    "print(A.sum())"
   ],
   "id": "28af9087aa2ecff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 4])\n",
      "tensor(780)\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.10 矩阵某轴求和（维度丢失）\n",
    "    指定张量沿哪一个轴来通过求和降低维度。\n",
    "    axis = 0垂直求和，axis = 1纵向求和，axis = 2横向求和"
   ],
   "id": "1613c1fd19e6933a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:16.996854Z",
     "start_time": "2025-07-23T06:27:16.982337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20*2).reshape(2,5,4)\n",
    "print(A)\n",
    "A_sum_axis0 = A.sum(axis = 0) # (2,5,4) 对第一个维度进行求和，剩下两个维度留下来了\n",
    "print(A_sum_axis0)\n",
    "print(A_sum_axis0.shape)"
   ],
   "id": "4d01921f73714528",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15],\n",
      "         [16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23],\n",
      "         [24, 25, 26, 27],\n",
      "         [28, 29, 30, 31],\n",
      "         [32, 33, 34, 35],\n",
      "         [36, 37, 38, 39]]])\n",
      "tensor([[20, 22, 24, 26],\n",
      "        [28, 30, 32, 34],\n",
      "        [36, 38, 40, 42],\n",
      "        [44, 46, 48, 50],\n",
      "        [52, 54, 56, 58]])\n",
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.043914Z",
     "start_time": "2025-07-23T06:27:17.029501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20*2).reshape(2,5,4)\n",
    "print(A)\n",
    "A_sum_axis1 = A.sum(axis=1) # (2,5,4) 对第二个维度进行求和，剩下两个维度留下来了\n",
    "print(A_sum_axis1)\n",
    "print(A_sum_axis1.shape)"
   ],
   "id": "aa1e83a4dbbb869f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15],\n",
      "         [16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23],\n",
      "         [24, 25, 26, 27],\n",
      "         [28, 29, 30, 31],\n",
      "         [32, 33, 34, 35],\n",
      "         [36, 37, 38, 39]]])\n",
      "tensor([[ 40,  45,  50,  55],\n",
      "        [140, 145, 150, 155]])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.091043Z",
     "start_time": "2025-07-23T06:27:17.076277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20*2).reshape(2,5,4)\n",
    "print(A)\n",
    "A_sum_axis1 = A.sum([0,1]) # (2,5,4) 对第一、二个维度进行求和，剩下一个维度留下来了\n",
    "print(A_sum_axis1)\n",
    "print(A_sum_axis1.shape)"
   ],
   "id": "5fb4f78e72545da7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15],\n",
      "         [16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23],\n",
      "         [24, 25, 26, 27],\n",
      "         [28, 29, 30, 31],\n",
      "         [32, 33, 34, 35],\n",
      "         [36, 37, 38, 39]]])\n",
      "tensor([180, 190, 200, 210])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.11 矩阵平均值\n",
    "    一个与求和相关的量是平均值（mean或average）。"
   ],
   "id": "d707a30476ff398b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.136267Z",
     "start_time": "2025-07-23T06:27:17.122579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "print(A.mean())\n",
    "print(A.sum()/A.numel()) # numel()是A的个数"
   ],
   "id": "565adf5089e58c1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.5000)\n",
      "tensor(9.5000)\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T05:04:39.898014Z",
     "start_time": "2025-07-25T05:04:38.637851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "print(A)\n",
    "print(A.mean(axis = 0))\n",
    "print(A.sum(axis=0))\n",
    "print(A.shape[0])\n",
    "print(A.sum(axis = 0)/A.shape[0])"
   ],
   "id": "7c7dfd3d5d7ec054",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "tensor([ 8.,  9., 10., 11.])\n",
      "tensor([40., 45., 50., 55.])\n",
      "5\n",
      "tensor([ 8.,  9., 10., 11.])\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.12 矩阵某轴求和（维度不丢失）\n",
    "    计算总和或均值时保持轴数不变。"
   ],
   "id": "db06866ddb9ce5de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.212938Z",
     "start_time": "2025-07-23T06:27:17.198383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "sum_A = A.sum(axis = 1, keepdims = True) # keepdims=True不丢掉维度，否则三维矩阵按一个维度求和就会变为二维矩阵，二维矩阵若按一个维度求和就会变为一维向量\n",
    "print(A)\n",
    "print(sum_A)\n",
    "print(sum_A.shape) # 维度没有丢失，方便使用广播"
   ],
   "id": "381b17d7f242b6bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "tensor([[ 6.],\n",
      "        [22.],\n",
      "        [38.],\n",
      "        [54.],\n",
      "        [70.]])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.13 矩阵广播\n",
    "    通过广播将 A 除以 sum_A。"
   ],
   "id": "14417125f4b47679"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.244219Z",
     "start_time": "2025-07-23T06:27:17.229295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "sum_A = A.sum(axis=1,keepdims=True) # keepdims=True不丢掉维度，否则三维矩阵按一个维度求和就会变为二维矩阵，二维矩阵若按一个维度求和就会变为一维向量\n",
    "print(A/sum_A)"
   ],
   "id": "d33e8d8535e0cec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
      "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
      "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
      "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
      "        [0.2286, 0.2429, 0.2571, 0.2714]])\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.14 矩阵某轴累加\n",
    "    某个轴计算A元素的累加总和。"
   ],
   "id": "b201127d726dca5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.275814Z",
     "start_time": "2025-07-23T06:27:17.260849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "print(A)\n",
    "print(A.cumsum(axis = 0)) # 按列向下累加"
   ],
   "id": "4b2a5cb13d83f2ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  6.,  8., 10.],\n",
      "        [12., 15., 18., 21.],\n",
      "        [24., 28., 32., 36.],\n",
      "        [40., 45., 50., 55.]])\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.15 向量点积\n",
    "    点积是相同位置的按元素成绩的和。"
   ],
   "id": "bf612d62c374613d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.322248Z",
     "start_time": "2025-07-23T06:27:17.307836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "x = torch.arange(4,dtype=torch.float32)\n",
    "y = torch.ones(4, dtype=torch.float32)\n",
    "print(x)\n",
    "print(y)\n",
    "print(torch.dot(x, y)) # 0*1 + 1*1 + 2*1 + 3*1 = 6"
   ],
   "id": "56340212837cc3c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.])\n",
      "tensor([1., 1., 1., 1.])\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    可以通过执行按元素乘法，然后进行求和来表示两个向量的点积。",
   "id": "b5659d91a043f519"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.354140Z",
     "start_time": "2025-07-23T06:27:17.339535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "x = torch.arange(4,dtype=torch.float32)\n",
    "y = torch.ones(4, dtype=torch.float32)\n",
    "print(torch.sum(x*y))"
   ],
   "id": "7cc0ffdc45f73e1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.16 矩阵向量积\n",
    "A是一个m×n的矩阵，x是一个n×1的矩阵，矩阵向量积$Ax$是一个长度为m的列向量，其第i个元素是点积$a^{⊤}_{i}x$。"
   ],
   "id": "1696d285b404f6bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.385025Z",
     "start_time": "2025-07-23T06:27:17.370798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "x = torch.arange(4,dtype=torch.float32)\n",
    "print(A)\n",
    "print(x)\n",
    "print(A.shape)\n",
    "print(x.shape)\n",
    "print(torch.mv(A, x))"
   ],
   "id": "6fbf67b1e6dfa699",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "tensor([0., 1., 2., 3.])\n",
      "torch.Size([5, 4])\n",
      "torch.Size([4])\n",
      "tensor([ 14.,  38.,  62.,  86., 110.])\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.17 矩阵相乘（线性代数相乘）\n",
    "    可以将矩阵-矩阵乘法AB看作是简单地执行m次矩阵-向量积，并将结果拼接在一起，形成一个n×m矩阵。"
   ],
   "id": "4187e0884e992d67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.417054Z",
     "start_time": "2025-07-23T06:27:17.401560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "B = torch.ones(4,3)\n",
    "print(A)\n",
    "print(B)\n",
    "torch.mm(A, B)"
   ],
   "id": "8dde95931d8561d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.],\n",
       "        [54., 54., 54.],\n",
       "        [70., 70., 70.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.18 矩阵L2范数\n",
    "L2 范数是向量元素平方和的平方根：\n",
    "$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$"
   ],
   "id": "5323efab25a23166"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.480245Z",
     "start_time": "2025-07-23T06:27:17.465399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "u = torch.tensor([3.0, -4.0])\n",
    "print(u)\n",
    "print(torch.norm(u)) # 3**3 + -4**-4 开根号 = 5"
   ],
   "id": "2a8f35e83698573f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3., -4.])\n",
      "tensor(5.)\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.19 矩阵L1范数\n",
    "$L_{1}$范数，它表示为向量元素的绝对值之和：$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|$"
   ],
   "id": "e052d1adcb735fc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.588951Z",
     "start_time": "2025-07-23T06:27:17.574654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "u = torch.tensor([3.0,-4.0])\n",
    "torch.abs(u).sum() # 3 + 4 = 7"
   ],
   "id": "b299e49100cb00c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6.3.20 矩阵F范数\n",
    "矩阵的弗罗贝尼乌斯范数（Frobenius norm）是矩阵元素的平方和的平方根：$$\\|\\mathbf{X}\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}$$"
   ],
   "id": "34090f4a9f934a71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:27:17.635974Z",
     "start_time": "2025-07-23T06:27:17.621367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "A = torch.ones((4,9))\n",
    "print(A)\n",
    "print(torch.norm(A)) # 把矩阵拉成一个向量，然后再求和    4 * 9 = 36 再开平方"
   ],
   "id": "8e39ed8a1420d413",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "execution_count": 109
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
