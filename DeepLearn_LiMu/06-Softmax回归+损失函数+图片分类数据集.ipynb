{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Softmax回归\n",
    "    Softmax回归虽然它的名字是回归，其实它是一个分类问题。"
   ],
   "id": "4f79e00614811587"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img.png)",
   "id": "1f19573c7c6b63f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. 回归VS分类",
   "id": "7ef11732b70acc3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_1.png)",
   "id": "2580ac4298c38860"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Kaggle分类问题",
   "id": "7c0fe18c96045abd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_2.png)\n",
    "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_3.png)\n",
    "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_4.png)"
   ],
   "id": "c7916f88bad39939"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. 回归到分类",
   "id": "44f2187d008b5801"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_5.png)\n",
    "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_6.png)\n",
    "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_7.png)\n",
    "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_8.png)"
   ],
   "id": "dcce37a7fe088193"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. 交叉熵损失",
   "id": "307f9c520277b4db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_9.png)",
   "id": "37796f5f2626167e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. 总结",
   "id": "242cc5efae2fb13a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_10.png)",
   "id": "8a12185a0c4beaea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7. 损失函数",
   "id": "1ae4fb11d5d9be14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_11.png)",
   "id": "54deb00c535b13e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 8. L2 Loss\n",
    "① 蓝色曲线为当y=0时，变换y'所获得的曲线。\n",
    "\n",
    "② 绿色曲线为当y=0时，变换y'所获得的曲线的似然函数，即$1^{-l(y,y')}$，似然函数呈高斯分布。最小化损失函数就是最大化似然函数。\n",
    "\n",
    "③ 橙色曲线为损失函数的梯度，梯度是一次函数，所以穿过原点。"
   ],
   "id": "4c4550c1658fae06"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_12.png)",
   "id": "497088167a045412"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "④ 当预测值y'跟真实值y隔的比较远的时候，(真实值y为0，预测值就是下面的曲线里的x轴)，梯度比较大，所以参数更新比较多。\n",
    "⑤ 随着预测值靠近真实值是，梯度越来越小，参数的更新越来越小。"
   ],
   "id": "8522017f1cd18046"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_13.png)",
   "id": "c80609e23796b431"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 9. L1 Loss",
   "id": "bf9fb4c61e017c2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_14.png)",
   "id": "5751f62f8e5458ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "① 相对L2 loss，L1 loss的梯度就是距离原点时，梯度也不是特别大，权重的更新也不是特别大。会带来很多稳定性的好处。\n",
    "\n",
    "② 他的缺点是在零点处不可导，并在零点处左右有±1的变化，这个不平滑性导致预测值与真实值靠的比较近的时候，优化到末期的时候，可能会不那么稳定。"
   ],
   "id": "337ed00aa209a43a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_15.png)",
   "id": "9c2725c7c774146a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 10. Huber's Robust Loss\n",
    "    结合L1 loss 和L2 loss损失。"
   ],
   "id": "1e0ed6aebfa6ec4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_16.png)\n",
    "![](Learn_Pictures/06-Softmax回归+损失函数+图片分类数据集/img_17.png)"
   ],
   "id": "594da4a8be5abd37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. 图像分类数据集\n",
    "    MINIST数据集是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单。\n",
    "    下面将使用类似但更复杂的Fashion-MNIST数据集。\n",
    "\n",
    "## 1.1 显示图片"
   ],
   "id": "cc096dc64c364f40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4112c9e33f0e98b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
